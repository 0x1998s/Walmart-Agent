# ğŸ›’ æ²ƒå°”ç›AI Agentå¹³å° - é›¶å”®åˆ†æAgent
# Walmart AI Agent Platform - Retail Analysis Agent

import json
import logging
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta

from app.agents.base_agent import BaseAgent, AgentCapability, AgentContext, AgentMessage, AgentTask

logger = logging.getLogger(__name__)


class RetailAnalysisAgent(BaseAgent):
    """é›¶å”®åˆ†æAgent - ä¸“é—¨å¤„ç†é›¶å”®ä¸šåŠ¡åˆ†æ"""
    
    def __init__(self, **kwargs):
        super().__init__(
            name="é›¶å”®åˆ†æåŠ©æ‰‹",
            description="ä¸“é—¨åˆ†æé›¶å”®ä¸šåŠ¡æ•°æ®ï¼ŒåŒ…æ‹¬é”€å”®è¶‹åŠ¿ã€å•†å“è¡¨ç°ã€å®¢æˆ·è¡Œä¸ºç­‰",
            capabilities=[
                AgentCapability.DATA_ANALYSIS,
                AgentCapability.NATURAL_LANGUAGE,
                AgentCapability.DOCUMENT_SEARCH,
                AgentCapability.REASONING,
                AgentCapability.PLANNING
            ],
            **kwargs
        )
    
    async def process_message(
        self,
        message: str,
        context: AgentContext,
        **kwargs
    ) -> AgentMessage:
        """å¤„ç†é›¶å”®åˆ†æç›¸å…³æ¶ˆæ¯"""
        
        # åˆ†ææ¶ˆæ¯ç±»å‹
        analysis_type = self._identify_analysis_type(message)
        
        # æœç´¢ç›¸å…³çŸ¥è¯†
        knowledge = await self.search_knowledge(
            query=message,
            collection_name="walmart_documents",
            n_results=5
        )
        
        # æ„å»ºåˆ†ææç¤º
        analysis_prompt = self._build_analysis_prompt(
            message, analysis_type, knowledge, context
        )
        
        # ç”Ÿæˆåˆ†æç»“æœ
        analysis_result = await self.generate_response(
            prompt=analysis_prompt,
            context=context,
            temperature=0.3,  # è¾ƒä½æ¸©åº¦ç¡®ä¿åˆ†æå‡†ç¡®æ€§
            max_tokens=2000
        )
        
        # å¦‚æœæ˜¯æ•°æ®åˆ†æè¯·æ±‚ï¼Œå°è¯•ç”Ÿæˆå›¾è¡¨å»ºè®®
        chart_suggestions = []
        if analysis_type in ["sales", "trend", "performance"]:
            chart_suggestions = self._generate_chart_suggestions(message, analysis_type)
        
        return AgentMessage(
            role="assistant",
            content=analysis_result,
            metadata={
                "analysis_type": analysis_type,
                "knowledge_sources": len(knowledge),
                "chart_suggestions": chart_suggestions,
                "confidence": self._calculate_confidence(knowledge)
            }
        )
    
    async def execute_task(
        self,
        task: AgentTask,
        context: AgentContext,
        **kwargs
    ) -> AgentTask:
        """æ‰§è¡Œé›¶å”®åˆ†æä»»åŠ¡"""
        
        task_type = task.metadata.get("task_type", "general_analysis")
        
        try:
            if task_type == "sales_analysis":
                result = await self._execute_sales_analysis(task, context)
            elif task_type == "inventory_analysis":
                result = await self._execute_inventory_analysis(task, context)
            elif task_type == "customer_analysis":
                result = await self._execute_customer_analysis(task, context)
            elif task_type == "trend_analysis":
                result = await self._execute_trend_analysis(task, context)
            else:
                result = await self._execute_general_analysis(task, context)
            
            task.output_data = result
            
        except Exception as e:
            logger.error(f"âŒ é›¶å”®åˆ†æä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            task.output_data = {
                "error": str(e),
                "task_type": task_type
            }
            raise
        
        return task
    
    def _identify_analysis_type(self, message: str) -> str:
        """è¯†åˆ«åˆ†æç±»å‹"""
        message_lower = message.lower()
        
        # é”€å”®åˆ†æ
        if any(word in message_lower for word in ["é”€å”®", "è¥æ”¶", "æ”¶å…¥", "ä¸šç»©"]):
            return "sales"
        
        # åº“å­˜åˆ†æ
        elif any(word in message_lower for word in ["åº“å­˜", "å­˜è´§", "è¡¥è´§", "ç¼ºè´§"]):
            return "inventory"
        
        # å®¢æˆ·åˆ†æ
        elif any(word in message_lower for word in ["å®¢æˆ·", "ç”¨æˆ·", "æ¶ˆè´¹è€…", "è´­ä¹°è¡Œä¸º"]):
            return "customer"
        
        # è¶‹åŠ¿åˆ†æ
        elif any(word in message_lower for word in ["è¶‹åŠ¿", "é¢„æµ‹", "å¢é•¿", "ä¸‹é™"]):
            return "trend"
        
        # å•†å“åˆ†æ
        elif any(word in message_lower for word in ["å•†å“", "äº§å“", "å“ç±»", "SKU"]):
            return "product"
        
        # ç«äº‰åˆ†æ
        elif any(word in message_lower for word in ["ç«äº‰", "å¯¹æ‰‹", "å¸‚åœºä»½é¢"]):
            return "competition"
        
        # ç»©æ•ˆåˆ†æ
        elif any(word in message_lower for word in ["ç»©æ•ˆ", "è¡¨ç°", "KPI", "æŒ‡æ ‡"]):
            return "performance"
        
        return "general"
    
    def _build_analysis_prompt(
        self,
        message: str,
        analysis_type: str,
        knowledge: List[Dict[str, Any]],
        context: AgentContext
    ) -> str:
        """æ„å»ºåˆ†ææç¤º"""
        
        # åŸºç¡€æç¤º
        base_prompt = f"""
ä½œä¸ºæ²ƒå°”ç›çš„ä¸“ä¸šé›¶å”®åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{message}
åˆ†æç±»å‹ï¼š{analysis_type}

ç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ï¼š
"""
        
        # æ·»åŠ çŸ¥è¯†åº“å†…å®¹
        for i, kb_item in enumerate(knowledge[:3]):  # åªä½¿ç”¨å‰3ä¸ªæœ€ç›¸å…³çš„ç»“æœ
            base_prompt += f"\n{i+1}. {kb_item['content'][:500]}...\n"
        
        # æ ¹æ®åˆ†æç±»å‹æ·»åŠ ä¸“ä¸šæŒ‡å¯¼
        type_guidance = {
            "sales": """
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œé”€å”®åˆ†æï¼š
- é”€å”®è¶‹åŠ¿å’Œå¢é•¿ç‡
- å…³é”®ä¸šç»©æŒ‡æ ‡(KPI)
- å­£èŠ‚æ€§å› ç´ å½±å“
- åŒºåŸŸ/æ¸ é“è¡¨ç°å·®å¼‚
- æ”¹è¿›å»ºè®®å’Œè¡ŒåŠ¨è®¡åˆ’
""",
            "inventory": """
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåº“å­˜åˆ†æï¼š
- åº“å­˜å‘¨è½¬ç‡å’Œå¥åº·åº¦
- ç¼ºè´§å’Œæ»é”€æƒ…å†µ
- è¡¥è´§ç­–ç•¥ä¼˜åŒ–
- æˆæœ¬æ§åˆ¶å»ºè®®
- åº“å­˜é¢„æµ‹å’Œè§„åˆ’
""",
            "customer": """
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œå®¢æˆ·åˆ†æï¼š
- å®¢æˆ·ç»†åˆ†å’Œç”»åƒ
- è´­ä¹°è¡Œä¸ºæ¨¡å¼
- å®¢æˆ·ä»·å€¼åˆ†æ
- æµå¤±é£é™©è¯„ä¼°
- å®¢æˆ·ä½“éªŒä¼˜åŒ–å»ºè®®
""",
            "trend": """
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œè¶‹åŠ¿åˆ†æï¼š
- å†å²æ•°æ®è¶‹åŠ¿è¯†åˆ«
- æœªæ¥å‘å±•é¢„æµ‹
- å½±å“å› ç´ åˆ†æ
- æœºä¼šä¸é£é™©è¯„ä¼°
- æˆ˜ç•¥å»ºè®®
""",
            "product": """
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œå•†å“åˆ†æï¼š
- å•†å“é”€å”®è¡¨ç°
- å“ç±»ç»“æ„ä¼˜åŒ–
- ä»·æ ¼ç­–ç•¥åˆ†æ
- æ–°å“å¼•å…¥å»ºè®®
- æ·˜æ±°å•†å“è¯†åˆ«
""",
            "performance": """
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œç»©æ•ˆåˆ†æï¼š
- å…³é”®æŒ‡æ ‡è¡¨ç°
- ç›®æ ‡è¾¾æˆæƒ…å†µ
- ç»©æ•ˆé©±åŠ¨å› ç´ 
- æ”¹è¿›æœºä¼šè¯†åˆ«
- è¡ŒåŠ¨è®¡åˆ’å»ºè®®
"""
        }
        
        base_prompt += type_guidance.get(analysis_type, """
è¯·æä¾›å…¨é¢çš„é›¶å”®ä¸šåŠ¡åˆ†æï¼ŒåŒ…æ‹¬ï¼š
- ç°çŠ¶åˆ†æ
- é—®é¢˜è¯†åˆ«
- æ”¹è¿›å»ºè®®
- å…·ä½“è¡ŒåŠ¨è®¡åˆ’
""")
        
        base_prompt += """
è¯·ç¡®ä¿åˆ†æç»“æœï¼š
1. åŸºäºæ•°æ®å’Œäº‹å®
2. ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º
3. æä¾›å¯æ‰§è¡Œçš„å»ºè®®
4. è€ƒè™‘æ²ƒå°”ç›çš„ä¸šåŠ¡ç‰¹ç‚¹
5. ä½¿ç”¨ä¸“ä¸šçš„é›¶å”®æœ¯è¯­

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ä¿æŒä¸“ä¸šå’Œå®¢è§‚çš„è¯­è°ƒã€‚
"""
        
        return base_prompt
    
    def _generate_chart_suggestions(self, message: str, analysis_type: str) -> List[Dict[str, str]]:
        """ç”Ÿæˆå›¾è¡¨å»ºè®®"""
        suggestions = []
        
        chart_mapping = {
            "sales": [
                {"type": "line", "title": "é”€å”®è¶‹åŠ¿å›¾", "description": "å±•ç¤ºé”€å”®é¢éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿"},
                {"type": "bar", "title": "åˆ†ç±»é”€å”®å¯¹æ¯”", "description": "å¯¹æ¯”ä¸åŒå•†å“ç±»åˆ«çš„é”€å”®è¡¨ç°"},
                {"type": "pie", "title": "é”€å”®å æ¯”åˆ†æ", "description": "å±•ç¤ºå„ç±»åˆ«åœ¨æ€»é”€å”®ä¸­çš„å æ¯”"}
            ],
            "trend": [
                {"type": "line", "title": "è¶‹åŠ¿é¢„æµ‹å›¾", "description": "æ˜¾ç¤ºå†å²è¶‹åŠ¿å’Œæœªæ¥é¢„æµ‹"},
                {"type": "area", "title": "ç´¯ç§¯è¶‹åŠ¿å›¾", "description": "å±•ç¤ºç´¯ç§¯å˜åŒ–è¶‹åŠ¿"}
            ],
            "performance": [
                {"type": "gauge", "title": "KPIä»ªè¡¨ç›˜", "description": "æ˜¾ç¤ºå…³é”®æŒ‡æ ‡å®Œæˆæƒ…å†µ"},
                {"type": "radar", "title": "å¤šç»´ç»©æ•ˆé›·è¾¾å›¾", "description": "å¤šè§’åº¦è¯„ä¼°ç»©æ•ˆè¡¨ç°"}
            ],
            "customer": [
                {"type": "scatter", "title": "å®¢æˆ·ä»·å€¼åˆ†å¸ƒ", "description": "å±•ç¤ºå®¢æˆ·ä»·å€¼å’Œæ´»è·ƒåº¦åˆ†å¸ƒ"},
                {"type": "funnel", "title": "å®¢æˆ·è½¬åŒ–æ¼æ–—", "description": "æ˜¾ç¤ºå®¢æˆ·è½¬åŒ–å„é˜¶æ®µæƒ…å†µ"}
            ]
        }
        
        return chart_mapping.get(analysis_type, [])
    
    def _calculate_confidence(self, knowledge: List[Dict[str, Any]]) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        if not knowledge:
            return 0.3
        
        # åŸºäºçŸ¥è¯†åº“åŒ¹é…åº¦å’Œæ•°é‡è®¡ç®—ç½®ä¿¡åº¦
        avg_score = sum(item.get("score", 0) for item in knowledge) / len(knowledge)
        knowledge_factor = min(len(knowledge) / 5, 1.0)  # çŸ¥è¯†æ•°é‡å› å­
        
        confidence = (avg_score * 0.7 + knowledge_factor * 0.3)
        return round(confidence, 2)
    
    async def _execute_sales_analysis(self, task: AgentTask, context: AgentContext) -> Dict[str, Any]:
        """æ‰§è¡Œé”€å”®åˆ†æä»»åŠ¡"""
        input_data = task.input_data
        
        # æ¨¡æ‹Ÿé”€å”®æ•°æ®åˆ†æ
        analysis_result = {
            "analysis_type": "sales",
            "time_period": input_data.get("time_period", "last_quarter"),
            "metrics": {
                "total_sales": 1250000,
                "growth_rate": 0.15,
                "average_transaction": 85.50,
                "units_sold": 14620
            },
            "trends": [
                {"period": "Q1", "sales": 1100000, "growth": 0.12},
                {"period": "Q2", "sales": 1200000, "growth": 0.09},
                {"period": "Q3", "sales": 1250000, "growth": 0.04}
            ],
            "insights": [
                "é”€å”®é¢è¿ç»­ä¸‰ä¸ªå­£åº¦ä¿æŒå¢é•¿",
                "Q3å¢é•¿ç‡æ”¾ç¼“ï¼Œéœ€è¦å…³æ³¨å¸‚åœºé¥±å’Œåº¦",
                "å¹³å‡å®¢å•ä»·æœ‰æ‰€æå‡ï¼Œè¯´æ˜å•†å“ç»“æ„ä¼˜åŒ–æœ‰æ•ˆ"
            ],
            "recommendations": [
                "åŠ å¼ºæ–°å®¢æˆ·è·å–ç­–ç•¥",
                "ä¼˜åŒ–é«˜ä»·å€¼å•†å“æ¨å¹¿",
                "å…³æ³¨å­£èŠ‚æ€§ä¿ƒé”€æœºä¼š"
            ]
        }
        
        return analysis_result
    
    async def _execute_inventory_analysis(self, task: AgentTask, context: AgentContext) -> Dict[str, Any]:
        """æ‰§è¡Œåº“å­˜åˆ†æä»»åŠ¡"""
        return {
            "analysis_type": "inventory",
            "inventory_health": {
                "turnover_rate": 6.2,
                "stock_coverage_days": 45,
                "out_of_stock_rate": 0.03,
                "excess_inventory_value": 180000
            },
            "category_performance": [
                {"category": "ç”µå­äº§å“", "turnover": 8.1, "status": "å¥åº·"},
                {"category": "æœè£…", "turnover": 4.5, "status": "éœ€å…³æ³¨"},
                {"category": "é£Ÿå“", "turnover": 12.3, "status": "ä¼˜ç§€"}
            ],
            "recommendations": [
                "ä¼˜åŒ–æœè£…ç±»åˆ«çš„é‡‡è´­ç­–ç•¥",
                "åŠ å¼ºéœ€æ±‚é¢„æµ‹å‡†ç¡®æ€§",
                "å»ºç«‹åŠ¨æ€å®‰å…¨åº“å­˜æœºåˆ¶"
            ]
        }
    
    async def _execute_customer_analysis(self, task: AgentTask, context: AgentContext) -> Dict[str, Any]:
        """æ‰§è¡Œå®¢æˆ·åˆ†æä»»åŠ¡"""
        return {
            "analysis_type": "customer",
            "customer_segments": [
                {"segment": "é«˜ä»·å€¼å®¢æˆ·", "count": 1250, "revenue_contribution": 0.45},
                {"segment": "å¸¸è§„å®¢æˆ·", "count": 8900, "revenue_contribution": 0.40},
                {"segment": "æ–°å®¢æˆ·", "count": 2100, "revenue_contribution": 0.15}
            ],
            "behavior_insights": [
                "é«˜ä»·å€¼å®¢æˆ·è´­ä¹°é¢‘æ¬¡ä¸ºæœˆå‡3.2æ¬¡",
                "ç§»åŠ¨ç«¯è´­ä¹°æ¯”ä¾‹æŒç»­å¢é•¿è‡³68%",
                "å®¢æˆ·å¤è´­ç‡è¾¾åˆ°73%"
            ],
            "recommendations": [
                "é’ˆå¯¹é«˜ä»·å€¼å®¢æˆ·æ¨å‡ºä¸“å±æœåŠ¡",
                "ä¼˜åŒ–ç§»åŠ¨è´­ç‰©ä½“éªŒ",
                "åˆ¶å®šæ–°å®¢æˆ·è½¬åŒ–ç­–ç•¥"
            ]
        }
    
    async def _execute_trend_analysis(self, task: AgentTask, context: AgentContext) -> Dict[str, Any]:
        """æ‰§è¡Œè¶‹åŠ¿åˆ†æä»»åŠ¡"""
        return {
            "analysis_type": "trend",
            "identified_trends": [
                {"trend": "çº¿ä¸Šè´­ç‰©å¢é•¿", "strength": "å¼º", "impact": "æ­£é¢"},
                {"trend": "å¯æŒç»­å•†å“éœ€æ±‚", "strength": "ä¸­", "impact": "æ­£é¢"},
                {"trend": "ä»·æ ¼æ•æ„Ÿåº¦ä¸Šå‡", "strength": "ä¸­", "impact": "è´Ÿé¢"}
            ],
            "predictions": {
                "next_quarter_growth": 0.08,
                "market_expansion_opportunity": "ä¸­ç­‰",
                "risk_level": "ä½"
            },
            "strategic_recommendations": [
                "åŠ å¤§çº¿ä¸Šæ¸ é“æŠ•èµ„",
                "æ‰©å±•å¯æŒç»­å•†å“å“ç±»",
                "ä¼˜åŒ–ä»·æ ¼ç­–ç•¥å’Œä¿ƒé”€æ´»åŠ¨"
            ]
        }
    
    async def _execute_general_analysis(self, task: AgentTask, context: AgentContext) -> Dict[str, Any]:
        """æ‰§è¡Œé€šç”¨åˆ†æä»»åŠ¡"""
        return {
            "analysis_type": "general",
            "summary": "å·²å®Œæˆç»¼åˆé›¶å”®ä¸šåŠ¡åˆ†æ",
            "key_findings": [
                "æ•´ä½“ä¸šåŠ¡è¡¨ç°ç¨³å®š",
                "å­˜åœ¨ä¼˜åŒ–æœºä¼š",
                "å»ºè®®æŒç»­ç›‘æ§å…³é”®æŒ‡æ ‡"
            ],
            "next_steps": [
                "æ·±å…¥åˆ†æå…·ä½“ä¸šåŠ¡é¢†åŸŸ",
                "åˆ¶å®šè¯¦ç»†æ”¹è¿›è®¡åˆ’",
                "å»ºç«‹å®šæœŸç›‘æ§æœºåˆ¶"
            ]
        }
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """
ä½ æ˜¯æ²ƒå°”ç›çš„ä¸“ä¸šé›¶å”®åˆ†æå¸ˆï¼Œæ‹¥æœ‰ä¸°å¯Œçš„é›¶å”®ä¸šåŠ¡ç»éªŒå’Œæ•°æ®åˆ†æèƒ½åŠ›ã€‚

ä½ çš„ä¸“é•¿åŒ…æ‹¬ï¼š
- é”€å”®æ•°æ®åˆ†æå’Œè¶‹åŠ¿é¢„æµ‹
- åº“å­˜ç®¡ç†å’Œä¼˜åŒ–
- å®¢æˆ·è¡Œä¸ºåˆ†æ
- å•†å“è¡¨ç°è¯„ä¼°
- å¸‚åœºç«äº‰åˆ†æ
- ä¸šåŠ¡ç»©æ•ˆè¯„ä¼°

è¯·å§‹ç»ˆä¿æŒä¸“ä¸šã€å®¢è§‚ã€åŸºäºæ•°æ®çš„åˆ†æé£æ ¼ï¼Œå¹¶æä¾›å¯æ‰§è¡Œçš„ä¸šåŠ¡å»ºè®®ã€‚
ä½¿ç”¨é›¶å”®è¡Œä¸šçš„ä¸“ä¸šæœ¯è¯­ï¼Œç¡®ä¿åˆ†æç»“æœå¯¹ä¸šåŠ¡å†³ç­–æœ‰å®é™…æŒ‡å¯¼æ„ä¹‰ã€‚
"""
    
    def _get_relevant_keywords(self) -> List[str]:
        """è·å–ç›¸å…³å…³é”®è¯"""
        return [
            "é”€å”®", "è¥æ”¶", "æ”¶å…¥", "ä¸šç»©", "åˆ†æ", "æ•°æ®",
            "åº“å­˜", "å­˜è´§", "è¡¥è´§", "ç¼ºè´§", "å‘¨è½¬",
            "å®¢æˆ·", "ç”¨æˆ·", "æ¶ˆè´¹è€…", "è´­ä¹°", "è¡Œä¸º",
            "å•†å“", "äº§å“", "å“ç±»", "SKU", "è¡¨ç°",
            "è¶‹åŠ¿", "é¢„æµ‹", "å¢é•¿", "ä¸‹é™", "å˜åŒ–",
            "ç«äº‰", "å¯¹æ‰‹", "å¸‚åœº", "ä»½é¢", "å®šä½",
            "ç»©æ•ˆ", "KPI", "æŒ‡æ ‡", "ç›®æ ‡", "è¾¾æˆ",
            "é›¶å”®", "æ²ƒå°”ç›", "é—¨åº—", "æ¸ é“", "ç”µå•†"
        ]
    
    def _get_default_collection(self) -> str:
        """è·å–é»˜è®¤çŸ¥è¯†åº“é›†åˆå"""
        return "walmart_documents"
